"""
MaxSpeeding Meta Ads æ™ºèƒ½æ—¥æŠ¥ç³»ç»Ÿ - æŠ¥å‘Šç”Ÿæˆå™¨

æ•´åˆæ‰€æœ‰åˆ†ææ¨¡å—ï¼Œç”Ÿæˆå®Œæ•´æ—¥æŠ¥
"""
from typing import Dict, List, Optional
from datetime import date
from loguru import logger

from data.meta_api import MetaAdsClient
from data.cache import DataCache
from analysis.trend import TrendAnalyzer
from analysis.benchmark import BenchmarkAnalyzer
from analysis.anomaly import AnomalyDetector
from report.templates import ReportTemplates
from config.settings import Settings


class ReportGenerator:
    """æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, settings: Settings):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨

        Args:
            settings: ç³»ç»Ÿé…ç½®
        """
        self.settings = settings
        self.cache = DataCache(
            expire_seconds=settings.CACHE_EXPIRE_SECONDS
        )
        self.trend_analyzer = TrendAnalyzer()
        self.benchmark_analyzer = BenchmarkAnalyzer()
        self.anomaly_detector = AnomalyDetector(settings)

    def generate_daily_report(
        self,
        report_date: Optional[str] = None,
        use_cache: bool = True
    ) -> Dict:
        """
        ç”Ÿæˆæ—¥æŠ¥

        Args:
            report_date: æŠ¥å‘Šæ—¥æœŸ (YYYY-MM-DD)ï¼Œé»˜è®¤ä»Šå¤©
            use_cache: æ˜¯å¦ä½¿ç”¨ç¼“å­˜

        Returns:
            æŠ¥å‘Šæ•°æ®å­—å…¸
        """
        if not report_date:
            report_date = date.today().strftime('%Y-%m-%d')

        logger.info(f"å¼€å§‹ç”Ÿæˆ {report_date} çš„æ—¥æŠ¥...")

        # è·å–æ•°æ®
        data = self._fetch_data(use_cache)

        # åˆ†ææ•°æ®
        analysis = self._analyze_data(data)

        # ç”ŸæˆæŠ¥å‘Š
        report = self._build_report(report_date, data, analysis)

        logger.info("æ—¥æŠ¥ç”Ÿæˆå®Œæˆ")
        return report

    def _fetch_data(self, use_cache: bool) -> Dict:
        """è·å–æ•°æ®"""
        cache_key = f"ads_data_{date.today().strftime('%Y-%m-%d')}"

        # å°è¯•ä»ç¼“å­˜è·å–
        if use_cache:
            cached = self.cache.get(cache_key)
            if cached:
                logger.info("ä½¿ç”¨ç¼“å­˜æ•°æ®")
                return cached

        # åˆå§‹åŒ– API å®¢æˆ·ç«¯
        api_client = MetaAdsClient(self.settings)

        # è·å–å¤šå‘¨æœŸæ•°æ®
        multi_period_data = api_client.get_multi_period_data(periods=[1, 3, 7])

        # èšåˆæ•°æ®
        aggregated = {}
        for period_days, raw_data in multi_period_data.items():
            aggregated[period_days] = api_client.aggregate_metrics(raw_data)

        # ä¿å­˜åˆ°ç¼“å­˜
        self.cache.set(cache_key, aggregated)

        return aggregated

    def _analyze_data(self, data: Dict) -> Dict:
        """åˆ†ææ•°æ®"""
        analysis = {}

        # å½“å‰æ•°æ®
        current_data = data.get(1, {})
        previous_data = data.get(3, {})

        # è¶‹åŠ¿åˆ†æ
        comparison = self.trend_analyzer.compare_periods(
            current_data,
            previous_data
        )
        trend_analysis = self.trend_analyzer.analyze_multi_period(data)
        analysis['trend'] = {
            'comparison': comparison,
            'multi_period': trend_analysis
        }

        # Benchmark åˆ†æ
        benchmark_evaluation = self.benchmark_analyzer.analyze_all_metrics(current_data)
        benchmark_score = self.benchmark_analyzer.get_overall_score(benchmark_evaluation)
        analysis['benchmark'] = {
            'evaluation': benchmark_evaluation,
            'score': benchmark_score
        }

        # å¼‚å¸¸æ£€æµ‹
        anomalies = self.anomaly_detector.detect_all(current_data)
        analysis['anomalies'] = {
            'list': anomalies,
            'formatted': self.anomaly_detector.format_anomalies(anomalies)
        }

        # ç”Ÿæˆæ™ºèƒ½å»ºè®®
        insights = self._generate_insights(
            comparison,
            trend_analysis,
            benchmark_evaluation,
            anomalies
        )
        analysis['insights'] = insights

        return analysis

    def _generate_insights(
        self,
        comparison: Dict,
        trend_analysis: Dict,
        benchmark_evaluation: Dict,
        anomalies: List
    ) -> List[str]:
        """ç”Ÿæˆæ™ºèƒ½å»ºè®®"""
        insights = []

        # åŸºäºè¶‹åŠ¿çš„å»ºè®®
        roas_trend = trend_analysis.get('metrics_trend', {}).get('roas', {})
        if roas_trend.get('trend_status') == 'positive':
            insights.append("âœ… ROAS æŒç»­ä¸Šå‡ï¼Œå½“å‰ä¼˜åŒ–ç­–ç•¥æœ‰æ•ˆï¼Œå»ºè®®ç»§ç»­ä¿æŒ")
        elif roas_trend.get('trend_status') == 'negative':
            insights.append("âš ï¸ ROAS æŒç»­ä¸‹é™ï¼Œå»ºè®®æ£€æŸ¥å—ä¼—å®šä½å’Œå¹¿å‘Šåˆ›æ„")

        # åŸºäºå¯¹æ¯”çš„å»ºè®®
        spend_change = comparison.get('spend', {}).get('change_percent', 0)
        conv_change = comparison.get('conversions', {}).get('change_percent', 0)

        if spend_change > 20 and conv_change < 10:
            insights.append("ğŸ“‰ èŠ±è´¹å¢åŠ ä½†è½¬åŒ–æœªåŒæ­¥å¢é•¿ï¼Œå»ºè®®ä¼˜åŒ–å‡ºä»·ç­–ç•¥")

        # åŸºäº Benchmark çš„å»ºè®®
        for metric, result in benchmark_evaluation.items():
            if result['is_alert']:
                insights.append(f"ğŸš¨ {metric} ä½äºè¡Œä¸šæ ‡å‡†ï¼Œéœ€è¦é‡ç‚¹å…³æ³¨å’Œä¼˜åŒ–")

        # åŸºäºå¼‚å¸¸çš„å»ºè®®
        for anomaly in anomalies:
            if anomaly.severity == 'critical' and anomaly.suggestion:
                insights.append(f"ğŸ’¡ {anomaly.suggestion}")

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        insights = list(dict.fromkeys(insights))  # å»é‡
        return insights[:5]  # æœ€å¤š5æ¡å»ºè®®

    def _build_report(
        self,
        report_date: str,
        data: Dict,
        analysis: Dict
    ) -> Dict:
        """æ„å»ºæŠ¥å‘Š"""
        current_data = data.get(1, {})
        comparison = analysis.get('trend', {}).get('comparison', {})
        trend_analysis = analysis.get('trend', {}).get('multi_period', {})
        anomalies_text = analysis.get('anomalies', {}).get('formatted', '')
        benchmark_eval = analysis.get('benchmark', {}).get('evaluation', {})
        benchmark_score = analysis.get('benchmark', {}).get('score', 0)
        insights = analysis.get('insights', [])

        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        text_report = ReportTemplates.full_report(
            report_date,
            current_data,
            trend_analysis,
            anomalies_text,
            benchmark_eval,
            benchmark_score,
            insights
        )

        return {
            'date': report_date,
            'data': current_data,
            'analysis': analysis,
            'text_report': text_report,
            'summary': {
                'spend': current_data.get('spend', 0),
                'clicks': current_data.get('clicks', 0),
                'conversions': current_data.get('conversions', 0),
                'roas': current_data.get('roas', 0),
                'cpc': current_data.get('cpc', 0),
                'benchmark_score': benchmark_score
            }
        }

    def save_report(self, report: Dict, output_path: str) -> None:
        """
        ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶

        Args:
            report: æŠ¥å‘Šæ•°æ®
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report['text_report'])

        logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
